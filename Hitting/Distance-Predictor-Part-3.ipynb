{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Distance Predictor Part 3**\n",
    "Author: Declan Costello\n",
    "\n",
    "Date: 8/19/2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3 Description**\n",
    "\n",
    "Here I Create pipelines with hyperparameter tuning Imputation, Scalling, One Hot encoding, and then use grid search for hyper parameter tuning utilizing the new features created in part 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Context**\n",
    "\n",
    "1. [Installation](#Installation)\n",
    "2. [Model Comparisons](#gridsearch-for-best-model)\n",
    "3. [Results](#Results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Installation**\n",
    "\n",
    "The following installs the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import  StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LinearRegression, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"c82b0e73-7f57-4461-88c8-ddaa39c9c436\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"c82b0e73-7f57-4461-88c8-ddaa39c9c436\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c82b0e73-7f57-4461-88c8-ddaa39c9c436\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.palettes import Spectral11\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import row\n",
    "output_notebook()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Import and Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('FE_data.csv')\n",
    "\n",
    "data.pop('Unnamed: 0')\n",
    "data.pop('hc_x')\n",
    "data.pop('hc_y')\n",
    "data.pop('events')#...................\n",
    "data.pop('woba_value')\n",
    "data.pop('hit_distance_sc_percentile')\n",
    "data.pop('launch_speed_percentile')\n",
    "data.pop('release_speed_percentile')\n",
    "data.pop('launch_angle_binned')\n",
    "data.pop('pull_percent_binned')\n",
    "data.pop('Pop_percentile')\n",
    "data.pop('pitch_type')\n",
    "\n",
    "feature_cols = ['launch_angle','launch_speed',\"release_speed\",\"fav_platoon_split_for_batter\",\"grouped_pitch_type\",\"domed\",\"game_elevation\",\"is_barrel\",\"Pop\",\"pull_percent\", \"spray_angle\"]\n",
    "X = data.loc[:, feature_cols]\n",
    "\n",
    "target_cols = ['hit_distance_sc']\n",
    "y = data.loc[:, target_cols]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using GridSearch to Find Best Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Possible Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('LR', LogisticRegression(random_state=42))])\n",
    "\n",
    "#Ridge\n",
    "pipe_ridge = Pipeline([('scl', StandardScaler()),\n",
    "                       ('PR', Ridge(random_state=42))])\n",
    "\n",
    "#RandomForestRegressor\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "                    ('RF',RandomForestRegressor(random_state=42))])\n",
    "\n",
    "#KNeighborsRegressor\n",
    "pipe_knn = Pipeline([('scl', StandardScaler()),\n",
    "                    ('KNN', KNeighborsRegressor())])\n",
    "\n",
    "#XGBRegressor\n",
    "pipe_xgb = Pipeline([('scl', StandardScaler()),\n",
    "                     ('XGB', XGBRegressor(random_state=42))])\n",
    "\n",
    "#PolynomialRegression\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))\n",
    "\n",
    "#ElasticNet\n",
    "pipe_en = Pipeline([('scl', StandardScaler()),\n",
    "                     ('EN', ElasticNet(random_state=42))])\n",
    "\n",
    "#PLSRegression\n",
    "pipe_pls = Pipeline([('scl', StandardScaler()),\n",
    "                     ('PLS', PLSRegression())])\n",
    "\n",
    "#Lasso\n",
    "pipe_lasso = Pipeline([('scl', StandardScaler()),\n",
    "                     ('LAS', linear_model.Lasso(random_state=42))])\n",
    "\n",
    "#MLPRegressor\n",
    "pipe_MLPR = Pipeline([('scl', StandardScaler()),\n",
    "                      ('MLPR', MLPRegressor())])\n",
    "\n",
    "#GradientBoostingRegressor\n",
    "pipe_GBR = Pipeline([('scl', StandardScaler()),\n",
    "                     ('GBR', GradientBoostingRegressor(random_state=42))])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Param Grids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [1, 2, 3, 4, 5, 6,10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "n_estimators = [5,10,15]\n",
    "learning_rates = [.1,.2,.3]\n",
    "\n",
    "#LogisticRegression\n",
    "lr_param_grid = [{'LR__penalty': ['l1', 'l2']}]\n",
    "\n",
    "#Ridge\n",
    "ridge_param_grid = [{'PR__alpha':param_range,\n",
    "                     'PR__fit_intercept':[True,False],\n",
    "                     'PR__copy_X':[True,False],\n",
    "                     'PR__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}]\n",
    "\n",
    "#RandomForestRegressor\n",
    "rf_param_grid = [{'RF__max_depth': param_range,\n",
    "                  'RF__n_estimators': param_range}]\n",
    "\n",
    "#KNeighborsRegressor\n",
    "knn_param_grid = [{'KNN__n_neighbors': param_range,\n",
    "                   'KNN__weights': ['uniform', 'distance'],\n",
    "                   'KNN__metric': ['euclidean', 'manhattan']}]\n",
    "\n",
    "#XGBRegressor\n",
    "xgb_param_grid = [{'XGB__learning_rate': learning_rates,\n",
    "                    'XGB__max_depth': param_range,\n",
    "                    'XGB__min_child_weight': param_range[:2],\n",
    "                    'XGB__subsample': param_range_fl,\n",
    "                    'XGB__n_estimators': n_estimators}]\n",
    "\n",
    "#PolynomialRegression\n",
    "pyr_param_grid = {'polynomialfeatures__degree': param_range[:4],\n",
    "              'linearregression__fit_intercept': [True, False]}\n",
    "\n",
    "#ElasticNet\n",
    "en_param_grid = [{'EN__alpha': param_range_fl,\n",
    "                    'EN__l1_ratio': param_range_fl,\n",
    "                    'EN__fit_intercept':[True,False],\n",
    "                    'EN__precompute':[True,False],\n",
    "                    'EN__copy_X':[True,False],\n",
    "                    'EN__warm_start': [True,False],\n",
    "                    'EN__selection': ['cyclic', 'random'],}]\n",
    "\n",
    "#PLSRegression\n",
    "pls_param_grid = [{'PLS__n_components': param_range,\n",
    "                    'PLS__scale': [True,False],}]\n",
    "\n",
    "#Lasso\n",
    "lasso_param_grid = [{'LAS__alpha': param_range_fl,\n",
    "                     'LAS__fit_intercept':[True, False],\n",
    "                     'LAS__precompute':[True, False],\n",
    "                     'LAS__copy_X':[True, False],\n",
    "                     'LAS__warm_start':[True, False],\n",
    "                     'LAS__positive': [True,False]}]\n",
    "\n",
    "\n",
    "# #MLPRegressor\n",
    "# pipe_MLPR = Pipeline([('scl', StandardScaler()),\n",
    "#                       ('MLPR', MLPRegressor())])\n",
    "\n",
    "#MLPRegressor\n",
    "MLPR_param_grid = [{'MLPR__alpha': [0.0001,0.0002,0.0003],\n",
    "                    'MLPR__max_iter': [150,200,250],\n",
    "                    'MLPR__shuffle': [False, True],\n",
    "                    'MLPR__verbose': [True, False],\n",
    "                    'MLPR__momentum': [0.7,0.9,1.1],\n",
    "                    'MLPR__nesterovs_momentum': [False,True],\n",
    "                    'MLPR__early_stopping': [True],\n",
    "                    'MLPR__warm_start': [True,False]}]\n",
    "\n",
    "#GradientBoostingRegressor\n",
    "GBR_param_grid = [{'GBR__max_depth': param_range,\n",
    "                   'GBR__learning_rate': learning_rates,\n",
    "                   'GBR__n_estimators': param_range,\n",
    "                   'GBR__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "                   'GBR__criterion': ['friedman_mse', 'squared_error'],\n",
    "                   'GBR__min_samples_split': [1,2,3],\n",
    "                   'GBR__min_samples_leaf': [1,2,3],\n",
    "                   'GBR__max_features': ['auto', 'sqrt', 'log2']}]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "lr_grid_search = GridSearchCV(estimator=pipe_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#Ridge\n",
    "ridge_grid_search = GridSearchCV(estimator=pipe_ridge,\n",
    "        param_grid=ridge_param_grid,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=3)\n",
    "\n",
    "#RandomForestRegressor\n",
    "rf_grid_search = GridSearchCV(estimator=pipe_rf,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#KNeighborsRegressor\n",
    "knn_grid_search = GridSearchCV(estimator=pipe_knn,\n",
    "        param_grid=knn_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#XGBRegressor\n",
    "xgb_grid_search = GridSearchCV(estimator=pipe_xgb,\n",
    "        param_grid=xgb_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#PolynomialRegression\n",
    "pyr_grid_search = GridSearchCV(PolynomialRegression(), \n",
    "                               param_grid=pyr_param_grid,\n",
    "                               scoring='neg_mean_absolute_error', \n",
    "                               cv=3)\n",
    "\n",
    "#ElasticNet\n",
    "en_grid_search = GridSearchCV(estimator=pipe_en,\n",
    "        param_grid=en_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#PLSRegression\n",
    "pls_grid_search = GridSearchCV(estimator=pipe_pls,\n",
    "        param_grid=pls_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#Lasso\n",
    "lasso_grid_search = GridSearchCV(estimator=pipe_lasso,\n",
    "        param_grid=lasso_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#MLPRegressor\n",
    "MLPR_grid_search = GridSearchCV(estimator=pipe_MLPR,\n",
    "        param_grid=MLPR_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n",
    "#GradientBoostingRegressor\n",
    "GBR_grid_search = GridSearchCV(estimator=pipe_GBR,\n",
    "        param_grid=GBR_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODEL FITTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 21777.51620845\n",
      "Validation score: -1.019492\n",
      "Iteration 2, loss = 12959.45386489\n",
      "Validation score: 0.077823\n",
      "Iteration 3, loss = 6166.63568507\n",
      "Validation score: 0.433408\n",
      "Iteration 4, loss = 4652.79555510\n",
      "Validation score: 0.501778\n",
      "Iteration 5, loss = 4202.37394071\n",
      "Validation score: 0.540798\n",
      "Iteration 6, loss = 3865.88776579\n",
      "Validation score: 0.578959\n",
      "Iteration 7, loss = 3538.90830614\n",
      "Validation score: 0.616116\n",
      "Iteration 8, loss = 3232.20591226\n",
      "Validation score: 0.650586\n",
      "Iteration 9, loss = 2955.17026299\n",
      "Validation score: 0.681358\n",
      "Iteration 10, loss = 2712.61649321\n",
      "Validation score: 0.708058\n",
      "Iteration 11, loss = 2504.17638015\n",
      "Validation score: 0.730921\n",
      "Iteration 12, loss = 2326.02859987\n",
      "Validation score: 0.750419\n",
      "Iteration 13, loss = 2172.28320442\n",
      "Validation score: 0.767211\n",
      "Iteration 14, loss = 2036.30333363\n",
      "Validation score: 0.782084\n",
      "Iteration 15, loss = 1912.33113723\n",
      "Validation score: 0.795662\n",
      "Iteration 16, loss = 1795.97721331\n",
      "Validation score: 0.808437\n",
      "Iteration 17, loss = 1684.45503170\n",
      "Validation score: 0.820537\n",
      "Iteration 18, loss = 1577.94263706\n",
      "Validation score: 0.832026\n",
      "Iteration 19, loss = 1476.74787129\n",
      "Validation score: 0.842916\n",
      "Iteration 20, loss = 1380.01612491\n",
      "Validation score: 0.853393\n",
      "Iteration 21, loss = 1286.52717554\n",
      "Validation score: 0.863461\n",
      "Iteration 22, loss = 1196.32622399\n",
      "Validation score: 0.873181\n",
      "Iteration 23, loss = 1109.89068780\n",
      "Validation score: 0.882519\n",
      "Iteration 24, loss = 1027.44855601\n",
      "Validation score: 0.891398\n",
      "Iteration 25, loss = 949.15329459\n",
      "Validation score: 0.899805\n",
      "Iteration 26, loss = 874.80832015\n",
      "Validation score: 0.907784\n",
      "Iteration 27, loss = 804.30579432\n",
      "Validation score: 0.915324\n",
      "Iteration 28, loss = 737.69897956\n",
      "Validation score: 0.922440\n",
      "Iteration 29, loss = 674.96108880\n",
      "Validation score: 0.929094\n",
      "Iteration 30, loss = 616.31359414\n",
      "Validation score: 0.935275\n",
      "Iteration 31, loss = 561.85950601\n",
      "Validation score: 0.940984\n",
      "Iteration 32, loss = 511.27764916\n",
      "Validation score: 0.946277\n",
      "Iteration 33, loss = 464.65997257\n",
      "Validation score: 0.951086\n",
      "Iteration 34, loss = 422.73859329\n",
      "Validation score: 0.955403\n",
      "Iteration 35, loss = 385.28010292\n",
      "Validation score: 0.959250\n",
      "Iteration 36, loss = 351.95308103\n",
      "Validation score: 0.962696\n",
      "Iteration 37, loss = 322.26493777\n",
      "Validation score: 0.965732\n",
      "Iteration 38, loss = 296.49485192\n",
      "Validation score: 0.968340\n",
      "Iteration 39, loss = 274.16096911\n",
      "Validation score: 0.970617\n",
      "Iteration 40, loss = 254.71075381\n",
      "Validation score: 0.972576\n",
      "Iteration 41, loss = 238.14086884\n",
      "Validation score: 0.974244\n",
      "Iteration 42, loss = 223.99004532\n",
      "Validation score: 0.975692\n",
      "Iteration 43, loss = 211.71752599\n",
      "Validation score: 0.976955\n",
      "Iteration 44, loss = 200.95062057\n",
      "Validation score: 0.978071\n",
      "Iteration 45, loss = 191.50081749\n",
      "Validation score: 0.979062\n",
      "Iteration 46, loss = 183.13914996\n",
      "Validation score: 0.979945\n",
      "Iteration 47, loss = 175.65119596\n",
      "Validation score: 0.980731\n",
      "Iteration 48, loss = 168.96418020\n",
      "Validation score: 0.981434\n",
      "Iteration 49, loss = 163.00017003\n",
      "Validation score: 0.982060\n",
      "Iteration 50, loss = 157.65181329\n",
      "Validation score: 0.982628\n",
      "Iteration 51, loss = 152.82242953\n",
      "Validation score: 0.983149\n",
      "Iteration 52, loss = 148.47582197\n",
      "Validation score: 0.983617\n",
      "Iteration 53, loss = 144.57823382\n",
      "Validation score: 0.984034\n",
      "Iteration 54, loss = 141.04534216\n",
      "Validation score: 0.984418\n",
      "Iteration 55, loss = 137.82643420\n",
      "Validation score: 0.984766\n",
      "Iteration 56, loss = 134.88554958\n",
      "Validation score: 0.985078\n",
      "Iteration 57, loss = 132.22608214\n",
      "Validation score: 0.985360\n",
      "Iteration 58, loss = 129.78375138\n",
      "Validation score: 0.985621\n",
      "Iteration 59, loss = 127.54595741\n",
      "Validation score: 0.985857\n",
      "Iteration 60, loss = 125.47770110\n",
      "Validation score: 0.986069\n",
      "Iteration 61, loss = 123.57952437\n",
      "Validation score: 0.986260\n",
      "Iteration 62, loss = 121.85255728\n",
      "Validation score: 0.986435\n",
      "Iteration 63, loss = 120.26034701\n",
      "Validation score: 0.986596\n",
      "Iteration 64, loss = 118.79799932\n",
      "Validation score: 0.986744\n",
      "Iteration 65, loss = 117.47431421\n",
      "Validation score: 0.986879\n",
      "Iteration 66, loss = 116.26098204\n",
      "Validation score: 0.987005\n",
      "Iteration 67, loss = 115.14052320\n",
      "Validation score: 0.987126\n",
      "Iteration 68, loss = 114.08778678\n",
      "Validation score: 0.987242\n",
      "Iteration 69, loss = 113.09240192\n",
      "Validation score: 0.987352\n",
      "Iteration 70, loss = 112.14520878\n",
      "Validation score: 0.987460\n",
      "Iteration 71, loss = 111.23324122\n",
      "Validation score: 0.987567\n",
      "Iteration 72, loss = 110.32859805\n",
      "Validation score: 0.987675\n",
      "Iteration 73, loss = 109.44683751\n",
      "Validation score: 0.987783\n",
      "Iteration 74, loss = 108.59233938\n",
      "Validation score: 0.987889\n",
      "Iteration 75, loss = 107.76319025\n",
      "Validation score: 0.987989\n",
      "Iteration 76, loss = 106.98755080\n",
      "Validation score: 0.988081\n",
      "Iteration 77, loss = 106.26450895\n",
      "Validation score: 0.988165\n",
      "Iteration 78, loss = 105.57887334\n",
      "Validation score: 0.988243\n",
      "Iteration 79, loss = 104.93555196\n",
      "Validation score: 0.988318\n",
      "Iteration 80, loss = 104.33139495\n",
      "Validation score: 0.988387\n",
      "Iteration 81, loss = 103.75413623\n",
      "Validation score: 0.988450\n",
      "Iteration 82, loss = 103.21131384\n",
      "Validation score: 0.988504\n",
      "Iteration 83, loss = 102.70088189\n",
      "Validation score: 0.988554\n",
      "Iteration 84, loss = 102.22997990\n",
      "Validation score: 0.988601\n",
      "Iteration 85, loss = 101.80272456\n",
      "Validation score: 0.988644\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 22146.39109600\n",
      "Validation score: -1.125449\n",
      "Iteration 2, loss = 14263.90193469\n",
      "Validation score: -0.044383\n",
      "Iteration 3, loss = 6867.04539678\n",
      "Validation score: 0.436465\n",
      "Iteration 4, loss = 4656.94912511\n",
      "Validation score: 0.541381\n",
      "Iteration 5, loss = 4000.97263150\n",
      "Validation score: 0.592994\n",
      "Iteration 6, loss = 3573.07462828\n",
      "Validation score: 0.634806\n",
      "Iteration 7, loss = 3207.81058343\n",
      "Validation score: 0.671627\n",
      "Iteration 8, loss = 2888.69505806\n",
      "Validation score: 0.703680\n",
      "Iteration 9, loss = 2612.76981429\n",
      "Validation score: 0.731391\n",
      "Iteration 10, loss = 2373.29415696\n",
      "Validation score: 0.755600\n",
      "Iteration 11, loss = 2163.25338052\n",
      "Validation score: 0.776948\n",
      "Iteration 12, loss = 1979.03889125\n",
      "Validation score: 0.795475\n",
      "Iteration 13, loss = 1820.88791883\n",
      "Validation score: 0.811220\n",
      "Iteration 14, loss = 1686.31705955\n",
      "Validation score: 0.824557\n",
      "Iteration 15, loss = 1570.57341999\n",
      "Validation score: 0.836093\n",
      "Iteration 16, loss = 1468.59840589\n",
      "Validation score: 0.846340\n",
      "Iteration 17, loss = 1376.02680055\n",
      "Validation score: 0.855708\n",
      "Iteration 18, loss = 1289.56767094\n",
      "Validation score: 0.864618\n",
      "Iteration 19, loss = 1206.31890982\n",
      "Validation score: 0.873358\n",
      "Iteration 20, loss = 1124.15319789\n",
      "Validation score: 0.882136\n",
      "Iteration 21, loss = 1041.91668488\n",
      "Validation score: 0.891042\n",
      "Iteration 22, loss = 959.62902113\n",
      "Validation score: 0.900021\n",
      "Iteration 23, loss = 877.75123059\n",
      "Validation score: 0.908917\n",
      "Iteration 24, loss = 797.51780463\n",
      "Validation score: 0.917569\n",
      "Iteration 25, loss = 720.10500068\n",
      "Validation score: 0.925815\n",
      "Iteration 26, loss = 646.71755268\n",
      "Validation score: 0.933537\n",
      "Iteration 27, loss = 578.27896861\n",
      "Validation score: 0.940659\n",
      "Iteration 28, loss = 515.39349718\n",
      "Validation score: 0.947120\n",
      "Iteration 29, loss = 458.56118255\n",
      "Validation score: 0.952870\n",
      "Iteration 30, loss = 408.15322082\n",
      "Validation score: 0.957920\n",
      "Iteration 31, loss = 364.11867350\n",
      "Validation score: 0.962317\n",
      "Iteration 32, loss = 326.04423159\n",
      "Validation score: 0.966093\n",
      "Iteration 33, loss = 293.41990915\n",
      "Validation score: 0.969302\n",
      "Iteration 34, loss = 265.72930474\n",
      "Validation score: 0.972017\n",
      "Iteration 35, loss = 242.27174500\n",
      "Validation score: 0.974324\n",
      "Iteration 36, loss = 222.37751726\n",
      "Validation score: 0.976270\n",
      "Iteration 37, loss = 205.73394845\n",
      "Validation score: 0.977869\n",
      "Iteration 38, loss = 191.69785427\n",
      "Validation score: 0.979229\n",
      "Iteration 39, loss = 179.70467779\n",
      "Validation score: 0.980406\n",
      "Iteration 40, loss = 169.32093877\n",
      "Validation score: 0.981442\n",
      "Iteration 41, loss = 160.28335446\n",
      "Validation score: 0.982357\n",
      "Iteration 42, loss = 152.43290062\n",
      "Validation score: 0.983149\n",
      "Iteration 43, loss = 145.70468459\n",
      "Validation score: 0.983822\n",
      "Iteration 44, loss = 140.03788957\n",
      "Validation score: 0.984386\n",
      "Iteration 45, loss = 135.27988811\n",
      "Validation score: 0.984863\n",
      "Iteration 46, loss = 131.26081663\n",
      "Validation score: 0.985270\n",
      "Iteration 47, loss = 127.85173405\n",
      "Validation score: 0.985618\n",
      "Iteration 48, loss = 124.93534713\n",
      "Validation score: 0.985918\n",
      "Iteration 49, loss = 122.39554928\n",
      "Validation score: 0.986183\n",
      "Iteration 50, loss = 120.15856660\n",
      "Validation score: 0.986418\n",
      "Iteration 51, loss = 118.17231543\n",
      "Validation score: 0.986630\n",
      "Iteration 52, loss = 116.38756973\n",
      "Validation score: 0.986826\n",
      "Iteration 53, loss = 114.75340031\n",
      "Validation score: 0.987009\n",
      "Iteration 54, loss = 113.25040498\n",
      "Validation score: 0.987181\n",
      "Iteration 55, loss = 111.85414078\n",
      "Validation score: 0.987340\n",
      "Iteration 56, loss = 110.55224681\n",
      "Validation score: 0.987486\n",
      "Iteration 57, loss = 109.35574125\n",
      "Validation score: 0.987618\n",
      "Iteration 58, loss = 108.26034937\n",
      "Validation score: 0.987745\n",
      "Iteration 59, loss = 107.23427029\n",
      "Validation score: 0.987863\n",
      "Iteration 60, loss = 106.26611434\n",
      "Validation score: 0.987971\n",
      "Iteration 61, loss = 105.35544631\n",
      "Validation score: 0.988074\n",
      "Iteration 62, loss = 104.50551479\n",
      "Validation score: 0.988168\n",
      "Iteration 63, loss = 103.70325226\n",
      "Validation score: 0.988255\n",
      "Iteration 64, loss = 102.96030702\n",
      "Validation score: 0.988333\n",
      "Iteration 65, loss = 102.26554253\n",
      "Validation score: 0.988404\n",
      "Iteration 66, loss = 101.61596375\n",
      "Validation score: 0.988472\n",
      "Iteration 67, loss = 100.99373845\n",
      "Validation score: 0.988535\n",
      "Iteration 68, loss = 100.39582602\n",
      "Validation score: 0.988594\n",
      "Iteration 69, loss = 99.81939059\n",
      "Validation score: 0.988649\n",
      "Iteration 70, loss = 99.27319197\n",
      "Validation score: 0.988702\n",
      "Iteration 71, loss = 98.75044898\n",
      "Validation score: 0.988753\n",
      "Iteration 72, loss = 98.24635942\n",
      "Validation score: 0.988803\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 22181.18559940\n",
      "Validation score: -1.120543\n",
      "Iteration 2, loss = 14061.55174999\n",
      "Validation score: -0.063545\n",
      "Iteration 3, loss = 6785.39122663\n",
      "Validation score: 0.394930\n",
      "Iteration 4, loss = 4694.10587721\n",
      "Validation score: 0.503581\n",
      "Iteration 5, loss = 4049.15150205\n",
      "Validation score: 0.562622\n",
      "Iteration 6, loss = 3619.49565077\n",
      "Validation score: 0.609271\n",
      "Iteration 7, loss = 3261.26749487\n",
      "Validation score: 0.648422\n",
      "Iteration 8, loss = 2956.94649170\n",
      "Validation score: 0.681457\n",
      "Iteration 9, loss = 2693.83435179\n",
      "Validation score: 0.710189\n",
      "Iteration 10, loss = 2457.87375623\n",
      "Validation score: 0.735903\n",
      "Iteration 11, loss = 2246.03688747\n",
      "Validation score: 0.758498\n",
      "Iteration 12, loss = 2061.59849558\n",
      "Validation score: 0.777767\n",
      "Iteration 13, loss = 1903.51448818\n",
      "Validation score: 0.794028\n",
      "Iteration 14, loss = 1768.14369949\n",
      "Validation score: 0.807953\n",
      "Iteration 15, loss = 1651.09256817\n",
      "Validation score: 0.820073\n",
      "Iteration 16, loss = 1548.04637200\n",
      "Validation score: 0.830881\n",
      "Iteration 17, loss = 1455.76241870\n",
      "Validation score: 0.840633\n",
      "Iteration 18, loss = 1371.61009208\n",
      "Validation score: 0.849690\n",
      "Iteration 19, loss = 1292.22396948\n",
      "Validation score: 0.858332\n",
      "Iteration 20, loss = 1215.46852971\n",
      "Validation score: 0.866759\n",
      "Iteration 21, loss = 1140.14783771\n",
      "Validation score: 0.875126\n",
      "Iteration 22, loss = 1065.32520752\n",
      "Validation score: 0.883515\n",
      "Iteration 23, loss = 990.71516827\n",
      "Validation score: 0.891943\n",
      "Iteration 24, loss = 916.10148217\n",
      "Validation score: 0.900369\n",
      "Iteration 25, loss = 842.08931310\n",
      "Validation score: 0.908683\n",
      "Iteration 26, loss = 769.59007050\n",
      "Validation score: 0.916749\n",
      "Iteration 27, loss = 699.95032955\n",
      "Validation score: 0.924451\n",
      "Iteration 28, loss = 633.88227919\n",
      "Validation score: 0.931764\n",
      "Iteration 29, loss = 571.78970143\n",
      "Validation score: 0.938609\n",
      "Iteration 30, loss = 514.26262268\n",
      "Validation score: 0.944879\n",
      "Iteration 31, loss = 461.68577525\n",
      "Validation score: 0.950567\n",
      "Iteration 32, loss = 414.44661019\n",
      "Validation score: 0.955615\n",
      "Iteration 33, loss = 372.66432768\n",
      "Validation score: 0.960062\n",
      "Iteration 34, loss = 336.00037716\n",
      "Validation score: 0.963965\n",
      "Iteration 35, loss = 304.07365362\n",
      "Validation score: 0.967362\n",
      "Iteration 36, loss = 276.41508692\n",
      "Validation score: 0.970294\n",
      "Iteration 37, loss = 252.71150809\n",
      "Validation score: 0.972762\n",
      "Iteration 38, loss = 232.69442151\n",
      "Validation score: 0.974851\n",
      "Iteration 39, loss = 215.67741538\n",
      "Validation score: 0.976646\n",
      "Iteration 40, loss = 201.04007280\n",
      "Validation score: 0.978187\n",
      "Iteration 41, loss = 188.50136203\n",
      "Validation score: 0.979513\n",
      "Iteration 42, loss = 177.81307297\n",
      "Validation score: 0.980634\n",
      "Iteration 43, loss = 168.73902463\n",
      "Validation score: 0.981582\n",
      "Iteration 44, loss = 161.00672572\n",
      "Validation score: 0.982384\n",
      "Iteration 45, loss = 154.38308928\n",
      "Validation score: 0.983063\n",
      "Iteration 46, loss = 148.69083689\n",
      "Validation score: 0.983634\n",
      "Iteration 47, loss = 143.82142222\n",
      "Validation score: 0.984125\n",
      "Iteration 48, loss = 139.65859365\n",
      "Validation score: 0.984552\n",
      "Iteration 49, loss = 136.02389938\n",
      "Validation score: 0.984929\n",
      "Iteration 50, loss = 132.81422344\n",
      "Validation score: 0.985256\n",
      "Iteration 51, loss = 129.97795061\n",
      "Validation score: 0.985545\n",
      "Iteration 52, loss = 127.45246188\n",
      "Validation score: 0.985804\n",
      "Iteration 53, loss = 125.22226194\n",
      "Validation score: 0.986034\n",
      "Iteration 54, loss = 123.21350812\n",
      "Validation score: 0.986247\n",
      "Iteration 55, loss = 121.35882468\n",
      "Validation score: 0.986445\n",
      "Iteration 56, loss = 119.67792190\n",
      "Validation score: 0.986622\n",
      "Iteration 57, loss = 118.15773588\n",
      "Validation score: 0.986783\n",
      "Iteration 58, loss = 116.77321824\n",
      "Validation score: 0.986930\n",
      "Iteration 59, loss = 115.49398850\n",
      "Validation score: 0.987068\n",
      "Iteration 60, loss = 114.30510420\n",
      "Validation score: 0.987196\n",
      "Iteration 61, loss = 113.19748286\n",
      "Validation score: 0.987315\n",
      "Iteration 62, loss = 112.16683736\n",
      "Validation score: 0.987428\n",
      "Iteration 63, loss = 111.20775663\n",
      "Validation score: 0.987535\n",
      "Iteration 64, loss = 110.31434819\n",
      "Validation score: 0.987634\n",
      "Iteration 65, loss = 109.49825790\n",
      "Validation score: 0.987726\n",
      "Iteration 66, loss = 108.73558718\n",
      "Validation score: 0.987813\n",
      "Iteration 67, loss = 108.01459026\n",
      "Validation score: 0.987894\n",
      "Iteration 68, loss = 107.33420165\n",
      "Validation score: 0.987967\n",
      "Iteration 69, loss = 106.69795770\n",
      "Validation score: 0.988035\n",
      "Iteration 70, loss = 106.09773207\n",
      "Validation score: 0.988097\n",
      "Iteration 71, loss = 105.52674168\n",
      "Validation score: 0.988155\n",
      "Iteration 72, loss = 104.98760840\n",
      "Validation score: 0.988212\n",
      "Iteration 73, loss = 104.47785807\n",
      "Validation score: 0.988263\n",
      "Iteration 74, loss = 103.99453798\n",
      "Validation score: 0.988311\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 21687.72754165\n",
      "Validation score: -0.977043\n",
      "Iteration 2, loss = 12972.31256892\n",
      "Validation score: 0.088983\n",
      "Iteration 3, loss = 6293.61340336\n",
      "Validation score: 0.443361\n",
      "Iteration 4, loss = 4665.02053940\n",
      "Validation score: 0.524771\n",
      "Iteration 5, loss = 4089.53132160\n",
      "Validation score: 0.573936\n",
      "Iteration 6, loss = 3684.00986269\n",
      "Validation score: 0.613549\n",
      "Iteration 7, loss = 3338.42715503\n",
      "Validation score: 0.648142\n",
      "Iteration 8, loss = 3038.01909299\n",
      "Validation score: 0.678106\n",
      "Iteration 9, loss = 2779.04709246\n",
      "Validation score: 0.704138\n",
      "Iteration 10, loss = 2554.51376607\n",
      "Validation score: 0.727069\n",
      "Iteration 11, loss = 2356.66633243\n",
      "Validation score: 0.747510\n",
      "Iteration 12, loss = 2181.65123629\n",
      "Validation score: 0.765614\n",
      "Iteration 13, loss = 2028.46988647\n",
      "Validation score: 0.781487\n",
      "Iteration 14, loss = 1895.31001073\n",
      "Validation score: 0.795318\n",
      "Iteration 15, loss = 1779.62371948\n",
      "Validation score: 0.807468\n",
      "Iteration 16, loss = 1677.60834383\n",
      "Validation score: 0.818372\n",
      "Iteration 17, loss = 1585.26373080\n",
      "Validation score: 0.828390\n",
      "Iteration 18, loss = 1499.40670119\n",
      "Validation score: 0.837828\n",
      "Iteration 19, loss = 1417.81236517\n",
      "Validation score: 0.846869\n",
      "Iteration 20, loss = 1338.88334160\n",
      "Validation score: 0.855645\n",
      "Iteration 21, loss = 1262.00624246\n",
      "Validation score: 0.864173\n",
      "Iteration 22, loss = 1187.03651108\n",
      "Validation score: 0.872499\n",
      "Iteration 23, loss = 1113.92132097\n",
      "Validation score: 0.880615\n",
      "Iteration 24, loss = 1042.71233874\n",
      "Validation score: 0.888524\n",
      "Iteration 25, loss = 973.40821452\n",
      "Validation score: 0.896166\n",
      "Iteration 26, loss = 906.23590486\n",
      "Validation score: 0.903556\n",
      "Iteration 27, loss = 841.13059547\n",
      "Validation score: 0.910718\n",
      "Iteration 28, loss = 777.86251724\n",
      "Validation score: 0.917650\n",
      "Iteration 29, loss = 716.41309261\n",
      "Validation score: 0.924347\n",
      "Iteration 30, loss = 657.12686008\n",
      "Validation score: 0.930769\n",
      "Iteration 31, loss = 600.47115682\n",
      "Validation score: 0.936824\n",
      "Iteration 32, loss = 547.57419723\n",
      "Validation score: 0.942444\n",
      "Iteration 33, loss = 498.46935379\n",
      "Validation score: 0.947647\n",
      "Iteration 34, loss = 452.97325309\n",
      "Validation score: 0.952443\n",
      "Iteration 35, loss = 411.43233702\n",
      "Validation score: 0.956754\n",
      "Iteration 36, loss = 374.39454928\n",
      "Validation score: 0.960570\n",
      "Iteration 37, loss = 341.80757067\n",
      "Validation score: 0.963913\n",
      "Iteration 38, loss = 313.24997046\n",
      "Validation score: 0.966838\n",
      "Iteration 39, loss = 288.18533495\n",
      "Validation score: 0.969396\n",
      "Iteration 40, loss = 266.12746549\n",
      "Validation score: 0.971647\n",
      "Iteration 41, loss = 246.63613858\n",
      "Validation score: 0.973634\n",
      "Iteration 42, loss = 229.53530709\n",
      "Validation score: 0.975368\n",
      "Iteration 43, loss = 214.68626836\n",
      "Validation score: 0.976864\n",
      "Iteration 44, loss = 201.94187200\n",
      "Validation score: 0.978154\n",
      "Iteration 45, loss = 190.94233674\n",
      "Validation score: 0.979272\n",
      "Iteration 46, loss = 181.35132610\n",
      "Validation score: 0.980258\n",
      "Iteration 47, loss = 172.88798065\n",
      "Validation score: 0.981133\n",
      "Iteration 48, loss = 165.38466192\n",
      "Validation score: 0.981909\n",
      "Iteration 49, loss = 158.61818630\n",
      "Validation score: 0.982601\n",
      "Iteration 50, loss = 152.50366298\n",
      "Validation score: 0.983221\n",
      "Iteration 51, loss = 147.04977386\n",
      "Validation score: 0.983771\n",
      "Iteration 52, loss = 142.20278496\n",
      "Validation score: 0.984259\n",
      "Iteration 53, loss = 137.88027993\n",
      "Validation score: 0.984696\n",
      "Iteration 54, loss = 133.99186194\n",
      "Validation score: 0.985082\n",
      "Iteration 55, loss = 130.54843934\n",
      "Validation score: 0.985429\n",
      "Iteration 56, loss = 127.52969757\n",
      "Validation score: 0.985739\n",
      "Iteration 57, loss = 124.82556661\n",
      "Validation score: 0.986023\n",
      "Iteration 58, loss = 122.37479360\n",
      "Validation score: 0.986289\n",
      "Iteration 59, loss = 120.14716089\n",
      "Validation score: 0.986529\n",
      "Iteration 60, loss = 118.17565920\n",
      "Validation score: 0.986747\n",
      "Iteration 61, loss = 116.41621163\n",
      "Validation score: 0.986945\n",
      "Iteration 62, loss = 114.83576892\n",
      "Validation score: 0.987125\n",
      "Iteration 63, loss = 113.38893744\n",
      "Validation score: 0.987286\n",
      "Iteration 64, loss = 112.05275438\n",
      "Validation score: 0.987431\n",
      "Iteration 65, loss = 110.83187000\n",
      "Validation score: 0.987567\n",
      "Iteration 66, loss = 109.70011613\n",
      "Validation score: 0.987693\n",
      "Iteration 67, loss = 108.67745762\n",
      "Validation score: 0.987805\n",
      "Iteration 68, loss = 107.73810195\n",
      "Validation score: 0.987908\n",
      "Iteration 69, loss = 106.87418956\n",
      "Validation score: 0.988003\n",
      "Iteration 70, loss = 106.09068857\n",
      "Validation score: 0.988088\n",
      "Iteration 71, loss = 105.37963635\n",
      "Validation score: 0.988165\n",
      "Iteration 72, loss = 104.74218353\n",
      "Validation score: 0.988235\n",
      "Iteration 73, loss = 104.15588766\n",
      "Validation score: 0.988300\n",
      "Iteration 74, loss = 103.61996676\n",
      "Validation score: 0.988360\n",
      "Iteration 75, loss = 103.12922163\n",
      "Validation score: 0.988415\n",
      "Iteration 76, loss = 102.67998951\n",
      "Validation score: 0.988465\n",
      "Iteration 77, loss = 102.26380081\n",
      "Validation score: 0.988511\n",
      "Iteration 78, loss = 101.87448659\n",
      "Validation score: 0.988556\n",
      "Iteration 79, loss = 101.50495378\n",
      "Validation score: 0.988598\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 22056.74159930\n",
      "Validation score: -1.110768\n",
      "Iteration 2, loss = 13779.96627842\n",
      "Validation score: -0.019120\n",
      "Iteration 3, loss = 6652.02350294\n",
      "Validation score: 0.426892\n",
      "Iteration 4, loss = 4707.71351745\n",
      "Validation score: 0.525797\n",
      "Iteration 5, loss = 4081.54029003\n",
      "Validation score: 0.577253\n",
      "Iteration 6, loss = 3672.70825539\n",
      "Validation score: 0.616508\n",
      "Iteration 7, loss = 3335.09409845\n",
      "Validation score: 0.651729\n",
      "Iteration 8, loss = 3032.50886255\n",
      "Validation score: 0.683048\n",
      "Iteration 9, loss = 2769.35473319\n",
      "Validation score: 0.710008\n",
      "Iteration 10, loss = 2542.99541128\n",
      "Validation score: 0.733150\n",
      "Iteration 11, loss = 2346.88053628\n",
      "Validation score: 0.753204\n",
      "Iteration 12, loss = 2174.23067571\n",
      "Validation score: 0.771041\n",
      "Iteration 13, loss = 2018.55213895\n",
      "Validation score: 0.787416\n",
      "Iteration 14, loss = 1876.39817670\n",
      "Validation score: 0.802099\n",
      "Iteration 15, loss = 1750.73132863\n",
      "Validation score: 0.815062\n",
      "Iteration 16, loss = 1639.29417994\n",
      "Validation score: 0.826536\n",
      "Iteration 17, loss = 1539.04996731\n",
      "Validation score: 0.836865\n",
      "Iteration 18, loss = 1447.11940717\n",
      "Validation score: 0.846378\n",
      "Iteration 19, loss = 1360.52669276\n",
      "Validation score: 0.855476\n",
      "Iteration 20, loss = 1276.96738651\n",
      "Validation score: 0.864368\n",
      "Iteration 21, loss = 1195.53950162\n",
      "Validation score: 0.873140\n",
      "Iteration 22, loss = 1115.05811640\n",
      "Validation score: 0.881930\n",
      "Iteration 23, loss = 1035.00864584\n",
      "Validation score: 0.890639\n",
      "Iteration 24, loss = 955.82104005\n",
      "Validation score: 0.899229\n",
      "Iteration 25, loss = 878.10638768\n",
      "Validation score: 0.907670\n",
      "Iteration 26, loss = 802.47698792\n",
      "Validation score: 0.915782\n",
      "Iteration 27, loss = 730.02168421\n",
      "Validation score: 0.923585\n",
      "Iteration 28, loss = 661.20392182\n",
      "Validation score: 0.930993\n",
      "Iteration 29, loss = 596.60818203\n",
      "Validation score: 0.937918\n",
      "Iteration 30, loss = 536.66638950\n",
      "Validation score: 0.944276\n",
      "Iteration 31, loss = 481.97904508\n",
      "Validation score: 0.950011\n",
      "Iteration 32, loss = 433.01134457\n",
      "Validation score: 0.955096\n",
      "Iteration 33, loss = 389.78659494\n",
      "Validation score: 0.959574\n",
      "Iteration 34, loss = 351.76393509\n",
      "Validation score: 0.963538\n",
      "Iteration 35, loss = 318.42881143\n",
      "Validation score: 0.967004\n",
      "Iteration 36, loss = 289.42761363\n",
      "Validation score: 0.970019\n",
      "Iteration 37, loss = 264.20580879\n",
      "Validation score: 0.972640\n",
      "Iteration 38, loss = 242.30958696\n",
      "Validation score: 0.974922\n",
      "Iteration 39, loss = 223.34224899\n",
      "Validation score: 0.976903\n",
      "Iteration 40, loss = 206.95384124\n",
      "Validation score: 0.978612\n",
      "Iteration 41, loss = 192.85295680\n",
      "Validation score: 0.980064\n",
      "Iteration 42, loss = 180.80866870\n",
      "Validation score: 0.981306\n",
      "Iteration 43, loss = 170.49121407\n",
      "Validation score: 0.982366\n",
      "Iteration 44, loss = 161.64527389\n",
      "Validation score: 0.983270\n",
      "Iteration 45, loss = 154.03220500\n",
      "Validation score: 0.984050\n",
      "Iteration 46, loss = 147.46148819\n",
      "Validation score: 0.984718\n",
      "Iteration 47, loss = 141.82514339\n",
      "Validation score: 0.985289\n",
      "Iteration 48, loss = 136.98164480\n",
      "Validation score: 0.985777\n",
      "Iteration 49, loss = 132.82486280\n",
      "Validation score: 0.986194\n",
      "Iteration 50, loss = 129.22778550\n",
      "Validation score: 0.986547\n",
      "Iteration 51, loss = 126.13855167\n",
      "Validation score: 0.986850\n",
      "Iteration 52, loss = 123.44730862\n",
      "Validation score: 0.987114\n",
      "Iteration 53, loss = 121.07317529\n",
      "Validation score: 0.987357\n",
      "Iteration 54, loss = 118.76020031\n",
      "Validation score: 0.987576\n",
      "Iteration 55, loss = 116.87212200\n",
      "Validation score: 0.987756\n",
      "Iteration 56, loss = 115.21532589\n",
      "Validation score: 0.987916\n",
      "Iteration 57, loss = 113.74030467\n",
      "Validation score: 0.988061\n",
      "Iteration 58, loss = 112.41154043\n",
      "Validation score: 0.988190\n",
      "Iteration 59, loss = 111.21177959\n",
      "Validation score: 0.988307\n",
      "Iteration 60, loss = 110.12070805\n",
      "Validation score: 0.988412\n",
      "Iteration 61, loss = 109.13260465\n",
      "Validation score: 0.988508\n",
      "Iteration 62, loss = 108.21729397\n",
      "Validation score: 0.988597\n",
      "Iteration 63, loss = 107.35110378\n",
      "Validation score: 0.988682\n",
      "Iteration 64, loss = 106.52071833\n",
      "Validation score: 0.988763\n",
      "Iteration 65, loss = 105.73395185\n",
      "Validation score: 0.988838\n",
      "Iteration 66, loss = 104.99425681\n",
      "Validation score: 0.988905\n",
      "Iteration 67, loss = 104.30253610\n",
      "Validation score: 0.988969\n",
      "Iteration 68, loss = 103.63891176\n",
      "Validation score: 0.989028\n",
      "Iteration 69, loss = 103.01454063\n",
      "Validation score: 0.989084\n",
      "Iteration 70, loss = 102.42580310\n",
      "Validation score: 0.989137\n",
      "Iteration 71, loss = 101.86769298\n",
      "Validation score: 0.989186\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 22147.76110404\n",
      "Validation score: -1.107739\n",
      "Iteration 2, loss = 13874.14705830\n",
      "Validation score: -0.028344\n",
      "Iteration 3, loss = 6743.35642012\n",
      "Validation score: 0.412350\n",
      "Iteration 4, loss = 4735.41150666\n",
      "Validation score: 0.515304\n",
      "Iteration 5, loss = 4091.36665305\n",
      "Validation score: 0.570704\n",
      "Iteration 6, loss = 3670.35201670\n",
      "Validation score: 0.613601\n",
      "Iteration 7, loss = 3314.59412565\n",
      "Validation score: 0.650343\n",
      "Iteration 8, loss = 3006.95282516\n",
      "Validation score: 0.681919\n",
      "Iteration 9, loss = 2739.82290425\n",
      "Validation score: 0.709594\n",
      "Iteration 10, loss = 2502.01882293\n",
      "Validation score: 0.734726\n",
      "Iteration 11, loss = 2287.46706861\n",
      "Validation score: 0.757297\n",
      "Iteration 12, loss = 2098.37818723\n",
      "Validation score: 0.776764\n",
      "Iteration 13, loss = 1935.92731793\n",
      "Validation score: 0.793342\n",
      "Iteration 14, loss = 1797.60672743\n",
      "Validation score: 0.807524\n",
      "Iteration 15, loss = 1677.77671238\n",
      "Validation score: 0.819890\n",
      "Iteration 16, loss = 1571.30443820\n",
      "Validation score: 0.831006\n",
      "Iteration 17, loss = 1474.64709668\n",
      "Validation score: 0.841273\n",
      "Iteration 18, loss = 1385.44682005\n",
      "Validation score: 0.850895\n",
      "Iteration 19, loss = 1301.51367684\n",
      "Validation score: 0.860063\n",
      "Iteration 20, loss = 1221.09951116\n",
      "Validation score: 0.868876\n",
      "Iteration 21, loss = 1142.62558673\n",
      "Validation score: 0.877554\n",
      "Iteration 22, loss = 1064.73302849\n",
      "Validation score: 0.886203\n",
      "Iteration 23, loss = 987.06808677\n",
      "Validation score: 0.894856\n",
      "Iteration 24, loss = 909.57378942\n",
      "Validation score: 0.903486\n",
      "Iteration 25, loss = 832.67866318\n",
      "Validation score: 0.911955\n",
      "Iteration 26, loss = 757.25037415\n",
      "Validation score: 0.920203\n",
      "Iteration 27, loss = 684.35360668\n",
      "Validation score: 0.928076\n",
      "Iteration 28, loss = 615.34462688\n",
      "Validation score: 0.935453\n",
      "Iteration 29, loss = 551.51175924\n",
      "Validation score: 0.942173\n",
      "Iteration 30, loss = 494.30461877\n",
      "Validation score: 0.948070\n",
      "Iteration 31, loss = 444.11472800\n",
      "Validation score: 0.953243\n",
      "Iteration 32, loss = 400.06338267\n",
      "Validation score: 0.957797\n",
      "Iteration 33, loss = 361.32765028\n",
      "Validation score: 0.961817\n",
      "Iteration 34, loss = 327.23611053\n",
      "Validation score: 0.965339\n",
      "Iteration 35, loss = 297.33207187\n",
      "Validation score: 0.968408\n",
      "Iteration 36, loss = 271.33306451\n",
      "Validation score: 0.971062\n",
      "Iteration 37, loss = 248.83414555\n",
      "Validation score: 0.973353\n",
      "Iteration 38, loss = 229.52394864\n",
      "Validation score: 0.975322\n",
      "Iteration 39, loss = 212.95800449\n",
      "Validation score: 0.977001\n",
      "Iteration 40, loss = 198.81350915\n",
      "Validation score: 0.978430\n",
      "Iteration 41, loss = 186.73217659\n",
      "Validation score: 0.979647\n",
      "Iteration 42, loss = 176.36052384\n",
      "Validation score: 0.980699\n",
      "Iteration 43, loss = 167.39375268\n",
      "Validation score: 0.981615\n",
      "Iteration 44, loss = 159.61049428\n",
      "Validation score: 0.982408\n",
      "Iteration 45, loss = 152.92123976\n",
      "Validation score: 0.983095\n",
      "Iteration 46, loss = 147.19202309\n",
      "Validation score: 0.983689\n",
      "Iteration 47, loss = 142.22319471\n",
      "Validation score: 0.984202\n",
      "Iteration 48, loss = 137.91200171\n",
      "Validation score: 0.984655\n",
      "Iteration 49, loss = 134.12309321\n",
      "Validation score: 0.985060\n",
      "Iteration 50, loss = 130.77815508\n",
      "Validation score: 0.985415\n",
      "Iteration 51, loss = 127.82696275\n",
      "Validation score: 0.985726\n",
      "Iteration 52, loss = 125.22201513\n",
      "Validation score: 0.985998\n",
      "Iteration 53, loss = 122.90488002\n",
      "Validation score: 0.986239\n",
      "Iteration 54, loss = 120.83273651\n",
      "Validation score: 0.986454\n",
      "Iteration 55, loss = 118.96154161\n",
      "Validation score: 0.986649\n",
      "Iteration 56, loss = 117.21911581\n",
      "Validation score: 0.986827\n",
      "Iteration 57, loss = 115.58669104\n",
      "Validation score: 0.986990\n",
      "Iteration 58, loss = 114.06137944\n",
      "Validation score: 0.987142\n",
      "Iteration 59, loss = 112.62987716\n",
      "Validation score: 0.987278\n",
      "Iteration 60, loss = 111.32518476\n",
      "Validation score: 0.987402\n",
      "Iteration 61, loss = 110.13751475\n",
      "Validation score: 0.987519\n",
      "Iteration 62, loss = 109.04634718\n",
      "Validation score: 0.987629\n",
      "Iteration 63, loss = 108.04373090\n",
      "Validation score: 0.987734\n",
      "Iteration 64, loss = 107.10440013\n",
      "Validation score: 0.987831\n",
      "Iteration 65, loss = 106.22340447\n",
      "Validation score: 0.987925\n",
      "Iteration 66, loss = 105.39699241\n",
      "Validation score: 0.988015\n",
      "Iteration 67, loss = 104.61681977\n",
      "Validation score: 0.988096\n",
      "Iteration 68, loss = 103.89258574\n",
      "Validation score: 0.988172\n",
      "Iteration 69, loss = 103.22363224\n",
      "Validation score: 0.988243\n",
      "Iteration 70, loss = 102.60656451\n",
      "Validation score: 0.988310\n",
      "Iteration 71, loss = 102.03428111\n",
      "Validation score: 0.988372\n",
      "Iteration 72, loss = 101.50423269\n",
      "Validation score: 0.988428\n",
      "Iteration 73, loss = 101.00971770\n",
      "Validation score: 0.988483\n",
      "Iteration 74, loss = 100.54639448\n",
      "Validation score: 0.988536\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 21769.32718571\n",
      "Validation score: -0.970890\n",
      "Iteration 2, loss = 13259.46548677\n",
      "Validation score: 0.064126\n",
      "Iteration 3, loss = 6458.73321500\n",
      "Validation score: 0.438341\n",
      "Iteration 4, loss = 4691.55562062\n",
      "Validation score: 0.535528\n",
      "Iteration 5, loss = 4092.49519045\n",
      "Validation score: 0.587217\n",
      "Iteration 6, loss = 3700.08187416\n",
      "Validation score: 0.626499\n",
      "Iteration 7, loss = 3354.91237818\n",
      "Validation score: 0.660379\n",
      "Iteration 8, loss = 3053.38017105\n",
      "Validation score: 0.687720\n",
      "Iteration 9, loss = 2800.83651259\n",
      "Validation score: 0.710704\n",
      "Iteration 10, loss = 2586.16133085\n",
      "Validation score: 0.730277\n",
      "Iteration 11, loss = 2398.99154675\n",
      "Validation score: 0.747940\n",
      "Iteration 12, loss = 2234.06335204\n",
      "Validation score: 0.763589\n",
      "Iteration 13, loss = 2088.09967157\n",
      "Validation score: 0.777398\n",
      "Iteration 14, loss = 1959.00242728\n",
      "Validation score: 0.790035\n",
      "Iteration 15, loss = 1845.24722075\n",
      "Validation score: 0.800624\n",
      "Iteration 16, loss = 1744.15425124\n",
      "Validation score: 0.811109\n",
      "Iteration 17, loss = 1654.88297849\n",
      "Validation score: 0.820007\n",
      "Iteration 18, loss = 1573.66244952\n",
      "Validation score: 0.828215\n",
      "Iteration 19, loss = 1498.14819389\n",
      "Validation score: 0.836357\n",
      "Iteration 20, loss = 1426.04670806\n",
      "Validation score: 0.844206\n",
      "Iteration 21, loss = 1355.67233295\n",
      "Validation score: 0.852096\n",
      "Iteration 22, loss = 1283.76436689\n",
      "Validation score: 0.860222\n",
      "Iteration 23, loss = 1211.47670151\n",
      "Validation score: 0.868683\n",
      "Iteration 24, loss = 1137.17678152\n",
      "Validation score: 0.877183\n",
      "Iteration 25, loss = 1063.10070235\n",
      "Validation score: 0.885680\n",
      "Iteration 26, loss = 988.71130593\n",
      "Validation score: 0.893994\n",
      "Iteration 27, loss = 914.83009242\n",
      "Validation score: 0.902549\n",
      "Iteration 28, loss = 841.53184648\n",
      "Validation score: 0.910677\n",
      "Iteration 29, loss = 770.26523655\n",
      "Validation score: 0.918607\n",
      "Iteration 30, loss = 701.75648482\n",
      "Validation score: 0.926256\n",
      "Iteration 31, loss = 637.68853045\n",
      "Validation score: 0.933086\n",
      "Iteration 32, loss = 578.46393160\n",
      "Validation score: 0.939662\n",
      "Iteration 33, loss = 522.63703329\n",
      "Validation score: 0.945670\n",
      "Iteration 34, loss = 472.61491423\n",
      "Validation score: 0.950997\n",
      "Iteration 35, loss = 428.32713046\n",
      "Validation score: 0.955576\n",
      "Iteration 36, loss = 389.51852000\n",
      "Validation score: 0.959552\n",
      "Iteration 37, loss = 355.63756045\n",
      "Validation score: 0.963155\n",
      "Iteration 38, loss = 326.01792182\n",
      "Validation score: 0.966000\n",
      "Iteration 39, loss = 300.45943196\n",
      "Validation score: 0.968934\n",
      "Iteration 40, loss = 277.93907080\n",
      "Validation score: 0.971065\n",
      "Iteration 41, loss = 258.46944578\n",
      "Validation score: 0.973164\n",
      "Iteration 42, loss = 241.39449034\n",
      "Validation score: 0.974904\n",
      "Iteration 43, loss = 226.50126455\n",
      "Validation score: 0.976461\n",
      "Iteration 44, loss = 213.16689585\n",
      "Validation score: 0.977903\n",
      "Iteration 45, loss = 201.70114051\n",
      "Validation score: 0.979076\n",
      "Iteration 46, loss = 191.28560603\n",
      "Validation score: 0.980092\n",
      "Iteration 47, loss = 182.07132872\n",
      "Validation score: 0.981059\n",
      "Iteration 48, loss = 173.83266857\n",
      "Validation score: 0.981884\n",
      "Iteration 49, loss = 166.33683797\n",
      "Validation score: 0.982749\n",
      "Iteration 50, loss = 159.62622759\n",
      "Validation score: 0.983427\n",
      "Iteration 51, loss = 153.44651402\n",
      "Validation score: 0.984135\n",
      "Iteration 52, loss = 147.94666149\n",
      "Validation score: 0.984695\n",
      "Iteration 53, loss = 143.12593426\n",
      "Validation score: 0.985119\n",
      "Iteration 54, loss = 138.66146220\n",
      "Validation score: 0.985653\n",
      "Iteration 55, loss = 134.75032900\n",
      "Validation score: 0.986077\n",
      "Iteration 56, loss = 131.13688106\n",
      "Validation score: 0.986339\n",
      "Iteration 57, loss = 128.27999925\n",
      "Validation score: 0.986758\n",
      "Iteration 58, loss = 125.44964333\n",
      "Validation score: 0.987047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 22206.20676916\n",
      "Validation score: -1.087817\n",
      "Iteration 2, loss = 14016.53930448\n",
      "Validation score: -0.030725\n",
      "Iteration 3, loss = 6868.94045752\n",
      "Validation score: 0.409540\n",
      "Iteration 4, loss = 4786.82275385\n",
      "Validation score: 0.519784\n",
      "Iteration 5, loss = 4076.50404486\n",
      "Validation score: 0.577679\n",
      "Iteration 6, loss = 3643.65740620\n",
      "Validation score: 0.617786\n",
      "Iteration 7, loss = 3318.58234147\n",
      "Validation score: 0.649612\n",
      "Iteration 8, loss = 3050.27994077\n",
      "Validation score: 0.676321\n",
      "Iteration 9, loss = 2811.08960566\n",
      "Validation score: 0.701669\n",
      "Iteration 10, loss = 2588.87711376\n",
      "Validation score: 0.724555\n",
      "Iteration 11, loss = 2389.49222855\n",
      "Validation score: 0.744515\n",
      "Iteration 12, loss = 2218.07798576\n",
      "Validation score: 0.761732\n",
      "Iteration 13, loss = 2072.98763013\n",
      "Validation score: 0.776339\n",
      "Iteration 14, loss = 1950.13414201\n",
      "Validation score: 0.788773\n",
      "Iteration 15, loss = 1844.96951364\n",
      "Validation score: 0.799804\n",
      "Iteration 16, loss = 1753.38366912\n",
      "Validation score: 0.809415\n",
      "Iteration 17, loss = 1671.25720180\n",
      "Validation score: 0.818283\n",
      "Iteration 18, loss = 1594.85788422\n",
      "Validation score: 0.826283\n",
      "Iteration 19, loss = 1522.46340337\n",
      "Validation score: 0.834241\n",
      "Iteration 20, loss = 1452.16869060\n",
      "Validation score: 0.841736\n",
      "Iteration 21, loss = 1383.81379934\n",
      "Validation score: 0.848917\n",
      "Iteration 22, loss = 1316.96838641\n",
      "Validation score: 0.856368\n",
      "Iteration 23, loss = 1250.75158989\n",
      "Validation score: 0.863595\n",
      "Iteration 24, loss = 1185.23490889\n",
      "Validation score: 0.870823\n",
      "Iteration 25, loss = 1119.57720425\n",
      "Validation score: 0.878198\n",
      "Iteration 26, loss = 1053.24798996\n",
      "Validation score: 0.885352\n",
      "Iteration 27, loss = 986.35748509\n",
      "Validation score: 0.893088\n",
      "Iteration 28, loss = 919.33564082\n",
      "Validation score: 0.900619\n",
      "Iteration 29, loss = 850.64393601\n",
      "Validation score: 0.908171\n",
      "Iteration 30, loss = 782.77046960\n",
      "Validation score: 0.915755\n",
      "Iteration 31, loss = 716.79772531\n",
      "Validation score: 0.922893\n",
      "Iteration 32, loss = 653.90645414\n",
      "Validation score: 0.929712\n",
      "Iteration 33, loss = 594.41401132\n",
      "Validation score: 0.936185\n",
      "Iteration 34, loss = 538.23727464\n",
      "Validation score: 0.942300\n",
      "Iteration 35, loss = 485.67563065\n",
      "Validation score: 0.948014\n",
      "Iteration 36, loss = 437.43907625\n",
      "Validation score: 0.953047\n",
      "Iteration 37, loss = 394.13620264\n",
      "Validation score: 0.957630\n",
      "Iteration 38, loss = 355.46529759\n",
      "Validation score: 0.961668\n",
      "Iteration 39, loss = 321.71408241\n",
      "Validation score: 0.965256\n",
      "Iteration 40, loss = 292.60995010\n",
      "Validation score: 0.968293\n",
      "Iteration 41, loss = 267.32442341\n",
      "Validation score: 0.971048\n",
      "Iteration 42, loss = 245.79523729\n",
      "Validation score: 0.973349\n",
      "Iteration 43, loss = 227.25173951\n",
      "Validation score: 0.975288\n",
      "Iteration 44, loss = 211.18520649\n",
      "Validation score: 0.977002\n",
      "Iteration 45, loss = 197.74541646\n",
      "Validation score: 0.978496\n",
      "Iteration 46, loss = 186.07741358\n",
      "Validation score: 0.979718\n",
      "Iteration 47, loss = 175.94626900\n",
      "Validation score: 0.980779\n",
      "Iteration 48, loss = 167.40628506\n",
      "Validation score: 0.981701\n",
      "Iteration 49, loss = 159.85680589\n",
      "Validation score: 0.982440\n",
      "Iteration 50, loss = 153.34059993\n",
      "Validation score: 0.983174\n",
      "Iteration 51, loss = 147.73040226\n",
      "Validation score: 0.983745\n",
      "Iteration 52, loss = 142.80697197\n",
      "Validation score: 0.984292\n",
      "Iteration 53, loss = 138.54029881\n",
      "Validation score: 0.984686\n",
      "Iteration 54, loss = 134.82560511\n",
      "Validation score: 0.985079\n",
      "Iteration 55, loss = 131.42176544\n",
      "Validation score: 0.985445\n",
      "Iteration 56, loss = 128.39037181\n",
      "Validation score: 0.985802\n",
      "Iteration 57, loss = 125.79227875\n",
      "Validation score: 0.986088\n",
      "Iteration 58, loss = 123.24064642\n",
      "Validation score: 0.986390\n",
      "Iteration 59, loss = 121.10717191\n",
      "Validation score: 0.986625\n",
      "Iteration 60, loss = 119.07810433\n",
      "Validation score: 0.986892\n",
      "Iteration 61, loss = 117.31095701\n",
      "Validation score: 0.987062\n",
      "Iteration 62, loss = 115.76316236\n",
      "Validation score: 0.987145\n",
      "Iteration 63, loss = 114.13059889\n",
      "Validation score: 0.987387\n",
      "Iteration 64, loss = 112.78559860\n",
      "Validation score: 0.987497\n",
      "Iteration 65, loss = 111.50316142\n",
      "Validation score: 0.987750\n",
      "Iteration 66, loss = 110.23739236\n",
      "Validation score: 0.987872\n",
      "Iteration 67, loss = 109.00325365\n",
      "Validation score: 0.988005\n",
      "Iteration 68, loss = 108.04249813\n",
      "Validation score: 0.988108\n",
      "Iteration 69, loss = 107.07354144\n",
      "Validation score: 0.988223\n",
      "Iteration 70, loss = 106.15610370\n",
      "Validation score: 0.988330\n",
      "Iteration 71, loss = 105.37212759\n",
      "Validation score: 0.988410\n",
      "Iteration 72, loss = 104.68524246\n",
      "Validation score: 0.988523\n",
      "Iteration 73, loss = 103.98091256\n",
      "Validation score: 0.988546\n",
      "Iteration 74, loss = 103.34631897\n",
      "Validation score: 0.988701\n"
     ]
    }
   ],
   "source": [
    "grids = [lr_grid_search, \n",
    "         ridge_grid_search, \n",
    "         rf_grid_search, \n",
    "         knn_grid_search, \n",
    "         xgb_grid_search, \n",
    "         pyr_grid_search,\n",
    "         en_grid_search, \n",
    "         pls_grid_search, \n",
    "         lasso_grid_search,\n",
    "         MLPR_grid_search,\n",
    "         GBR_grid_search]\n",
    "\n",
    "for pipe in grids:\n",
    "    pipe.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The Best Model is XGBoost!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('line_color', 9), ('top', 3), ('x', 3)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('fill_color', 9), ('line_color', 9), ('top', 3), ('x', 3)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('fill_color', 9), ('hatch_color', 9), ('line_color', 9), ('top', 3), ('x', 3)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('line_color', 9), ('top', 3), ('x', 3)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('fill_color', 9), ('line_color', 9), ('top', 3), ('x', 3)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('fill_color', 9), ('hatch_color', 9), ('line_color', 9), ('top', 3), ('x', 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"ac46d1b5-126d-4eab-87a7-b0dee827ebc2\" data-root-id=\"p1079\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"3a138745-ecbb-4baa-a9be-6ca6274ff6bb\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"p1079\",\"attributes\":{\"children\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1040\",\"attributes\":{\"width\":700,\"height\":700,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1050\",\"attributes\":{\"factors\":[\"BR\",\"GBR\",\"MLPR\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1042\",\"attributes\":{\"start\":0}},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1051\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1052\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1043\",\"attributes\":{\"text\":\"R2 (we want higher score)\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1076\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1070\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1071\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1072\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":[\"BR\",\"GBR\",\"MLPR\"],\"shape\":[3],\"dtype\":\"object\",\"order\":\"little\"}],[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"jRmAptk24D+qz5XrxanvPzC7ry2Cs+8/\"},\"shape\":[3],\"dtype\":\"float64\",\"order\":\"little\"}],[\"line_color\",[\"#3288bd\",\"#66c2a5\",\"#abdda4\",\"#e6f598\",\"#ffffbf\",\"#fee08b\",\"#fdae61\",\"#f46d43\",\"#d53e4f\"]],[\"fill_color\",[\"#3288bd\",\"#66c2a5\",\"#abdda4\",\"#e6f598\",\"#ffffbf\",\"#fee08b\",\"#fdae61\",\"#f46d43\",\"#d53e4f\"]],[\"hatch_color\",[\"#3288bd\",\"#66c2a5\",\"#abdda4\",\"#e6f598\",\"#ffffbf\",\"#fee08b\",\"#fdae61\",\"#f46d43\",\"#d53e4f\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1077\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1078\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1073\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"field\",\"field\":\"line_color\"},\"fill_color\":{\"type\":\"field\",\"field\":\"fill_color\"},\"hatch_color\":{\"type\":\"field\",\"field\":\"hatch_color\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1074\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"field\",\"field\":\"line_color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"fill_color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"hatch_color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1075\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"field\",\"field\":\"line_color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"fill_color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"hatch_color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1049\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1063\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1064\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1065\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1066\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1067\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1068\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1069\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1058\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1059\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1060\"},\"axis_label\":\"R^2\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1061\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1053\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1054\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1055\"},\"axis_label\":\"Models\",\"major_label_orientation\":1,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1056\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1057\",\"attributes\":{\"axis\":{\"id\":\"p1053\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1062\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1058\"}}}]}},{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1001\",\"attributes\":{\"width\":700,\"height\":700,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1011\",\"attributes\":{\"factors\":[\"BR\",\"GBR\",\"MLPR\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1003\",\"attributes\":{\"start\":0}},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1012\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1013\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1004\",\"attributes\":{\"text\":\"MAE (we want lower score)\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1037\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1031\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1032\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1033\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":[\"BR\",\"GBR\",\"MLPR\"],\"shape\":[3],\"dtype\":\"object\",\"order\":\"little\"}],[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"HqH9pL3CU0C5XesfLIAjQEpNOb+CCSFA\"},\"shape\":[3],\"dtype\":\"float64\",\"order\":\"little\"}],[\"line_color\",[\"#3288bd\",\"#66c2a5\",\"#abdda4\",\"#e6f598\",\"#ffffbf\",\"#fee08b\",\"#fdae61\",\"#f46d43\",\"#d53e4f\"]],[\"fill_color\",[\"#3288bd\",\"#66c2a5\",\"#abdda4\",\"#e6f598\",\"#ffffbf\",\"#fee08b\",\"#fdae61\",\"#f46d43\",\"#d53e4f\"]],[\"hatch_color\",[\"#3288bd\",\"#66c2a5\",\"#abdda4\",\"#e6f598\",\"#ffffbf\",\"#fee08b\",\"#fdae61\",\"#f46d43\",\"#d53e4f\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1038\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1039\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1034\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"field\",\"field\":\"line_color\"},\"fill_color\":{\"type\":\"field\",\"field\":\"fill_color\"},\"hatch_color\":{\"type\":\"field\",\"field\":\"hatch_color\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1035\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"field\",\"field\":\"line_color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"fill_color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"hatch_color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1036\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"field\",\"field\":\"line_color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"fill_color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"hatch_color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1010\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1024\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1025\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1026\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1027\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1028\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1029\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1030\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1019\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1020\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1021\"},\"axis_label\":\"MAE (Feet)\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1022\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1014\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1015\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1016\"},\"axis_label\":\"Models\",\"major_label_orientation\":1,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1017\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1018\",\"attributes\":{\"axis\":{\"id\":\"p1014\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1023\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1019\"}}}]}}]}}]}};\n  const render_items = [{\"docid\":\"3a138745-ecbb-4baa-a9be-6ca6274ff6bb\",\"roots\":{\"p1079\":\"ac46d1b5-126d-4eab-87a7-b0dee827ebc2\"},\"root_ids\":[\"p1079\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1079"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_dict = {#0: 'Logistic Regression', \n",
    "            #  1: 'Ridge', \n",
    "            #  2: 'Random Forest', \n",
    "            #  3: 'K-Nearest Neighbors', \n",
    "            #  4: 'XGBoost', \n",
    "            #  5: 'Poly', \n",
    "            #  6: 'Elastic Net',\n",
    "            #  7: 'PLS', \n",
    "            #  8: 'Lasso',\n",
    "             0: 'MLPR',\n",
    "             1: 'GBR',\n",
    "             2: 'BR'}\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model','Test Accuracy','MAE','R2','Test Accuracy'])\n",
    "\n",
    "for i, model in enumerate(grids):\n",
    "    preds = model.predict(X_valid)\n",
    "    results_df.loc[i] = [grid_dict[i],model.score(X_valid,y_valid),mean_absolute_error(y_valid, preds),r2_score(y_valid, preds), model.score(X_valid,y_valid)]\n",
    "\n",
    "results_df = results_df.sort_values('MAE', ascending=False)\n",
    "\n",
    "# Set the x_range to the list of categories above\n",
    "p = figure(x_range=results_df.Model, width=700, height=700, title=\"MAE\")\n",
    "\n",
    "# Categorical values can also be used as coordinates\n",
    "p.vbar(x=results_df.Model, top=results_df.MAE, width=0.9,color=Spectral11)\n",
    "\n",
    "# Set some properties to make the plot look better\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "p.xaxis.major_label_orientation = 1\n",
    "p.xaxis.axis_label = 'Models'\n",
    "p.yaxis.axis_label = 'MAE (Feet)'\n",
    "\n",
    "\n",
    "\n",
    "# Set the x_range to the list of categories above\n",
    "z = figure(x_range=results_df.Model, width=700, height=700, title=\"R2 (we want higher score)\")\n",
    "\n",
    "# Categorical values can also be used as coordinates\n",
    "z.vbar(x=results_df.Model, top=results_df.R2, width=0.9, color=Spectral11)\n",
    "\n",
    "# Set some properties to make the plot look better\n",
    "z.xgrid.grid_line_color = None\n",
    "z.y_range.start = 0\n",
    "\n",
    "z.xaxis.major_label_orientation = 1\n",
    "z.xaxis.axis_label = 'Models'\n",
    "z.yaxis.axis_label = 'R^2'\n",
    "\n",
    "show(row(z,p))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TODO**\n",
    "\n",
    "- Use XGBoost in Part 4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
